{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "#---------------------------------------------\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#---------------------------------------------\n",
    "# Specific libraries\n",
    "from scipy import signal # Signal analysis\n",
    "# Math utils\n",
    "import math\n",
    "# To measure execution times\n",
    "from tqdm import tqdm\n",
    "\n",
    "#---------------------------------------------\n",
    "# Files managing\n",
    "import os\n",
    "\n",
    "#---------------------------------------------\n",
    "# Animations\n",
    "import imageio.v2 as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT READING FUNCTIONS (NBODY_SH1)\n",
    "\n",
    "#---------------------------------------------\n",
    "# Read the input file:\n",
    "#\n",
    "# N = number of particles\n",
    "# t_0 = initial time\n",
    "# particles_0 = collection of mass + 6D position/velocity vector for every particle in the system\n",
    "# The shape of particles is: [[m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1], \n",
    "#                             [m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2],\n",
    "#                             ...,\n",
    "#                             [m_N x_N, y_N, z_N, vx_N, vy_N, vz_N]]\n",
    "#\n",
    "# Returns:\n",
    "#         a snapshot (\"snapshot_0\") of the system at the initial condition in the shape:\n",
    "#         [N, t_0, particles_0] :   [N, t_0, [[m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1], \n",
    "#                                             [m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2],\n",
    "#                                             ...,\n",
    "#                                             [m_N x_N, y_N, z_N, vx_N, vy_N, vz_N]]]\n",
    "#\n",
    "# Input file is structured as follow:\n",
    "#\n",
    "# N\n",
    "# t_0\n",
    "# m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1\n",
    "# m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2\n",
    "# ...\n",
    "# m_N x_N, y_N, z_N, vx_N, vy_N, vz_N\n",
    "def read_input_nbodysh1(input_file_path):\n",
    "    input_file = open(input_file_path)\n",
    "\n",
    "    # readline() reads the first line and returns it as a string\n",
    "    N = int(input_file.readline())\n",
    "    t_0 = float(input_file.readline())\n",
    "\n",
    "    # readlines() reads all the remaining lines and returns them into a list of strings\n",
    "    particles_0 = input_file.readlines()\n",
    "\n",
    "    input_file.close()\n",
    "\n",
    "    # Convert the list of strings into a list of lists of number\n",
    "    for i in range(len(particles_0)):\n",
    "        # split() splits a string based on a separator (default is ' ') and returns a list of strings\n",
    "        particles_0[i] = particles_0[i].split()\n",
    "\n",
    "        # Convert the elements of each splitted string into numbers\n",
    "        for j in range(len(particles_0[i])):\n",
    "            particles_0[i][j] = float(particles_0[i][j])\n",
    "\n",
    "    snapshot_0 = [N, t_0, particles_0]\n",
    "\n",
    "    return snapshot_0\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Read the output file:\n",
    "# Output file is structured as follow:\n",
    "#\n",
    "# N\n",
    "# t_1\n",
    "# m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1\n",
    "# m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2\n",
    "# ...\n",
    "# m_N x_N, y_N, z_N, vx_N, vy_N, vz_N\n",
    "# N\n",
    "# t_2\n",
    "# m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1\n",
    "# m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2\n",
    "# ...\n",
    "# m_N x_N, y_N, z_N, vx_N, vy_N, vz_N\n",
    "#\n",
    "# ...\n",
    "#\n",
    "# N\n",
    "# t_f\n",
    "# m_1 x_1, y_1, z_1, vx_1, vy_1, vz_1\n",
    "# m_2 x_2, y_2, z_2, vx_2, vy_2, vz_2\n",
    "# ...\n",
    "# m_N x_N, y_N, z_N, vx_N, vy_N, vz_N\n",
    "#\n",
    "# Returns a list of snapshot of the evolved system (t>t_0)\n",
    "# See read_input for details on the snapshots\n",
    "def read_output_nbodysh1(output_file_path):\n",
    "    output_file = open(output_file_path)\n",
    "\n",
    "    # List to store all the snapshots in the output file\n",
    "    snapshots = []\n",
    "\n",
    "    # Try except here detects the EOF\n",
    "    # int() throws an exception when tries to convert something different than a number\n",
    "    while True:\n",
    "        try:\n",
    "            N = int(output_file.readline())\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # Line after N is the time stamp of the snapshot\n",
    "        t_stamp = float(output_file.readline())\n",
    "\n",
    "        # Collect strings of mass + 6D position/velocity vector N times (for N particles)\n",
    "        particles = [output_file.readline() for i in range (N)]\n",
    "\n",
    "        # Convert the list of strings into a list of lists of number (same as for read_input())\n",
    "        for i in range(len(particles)):\n",
    "            particles[i] = particles[i].split()\n",
    "\n",
    "            for j in range(len(particles[i])):\n",
    "                particles[i][j] = float(particles[i][j])\n",
    "        \n",
    "        # Append the snapshot [N, t_stamp, particles] to the snapshots list\n",
    "        snapshots.append([N, t_stamp, particles])\n",
    "\n",
    "    output_file.close()\n",
    "    \n",
    "    return snapshots\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Returns the complete list of snapshots of the system (including the initial one)\n",
    "#\n",
    "# How to navigate the snapshots:\n",
    "# 1) Choose the snapshot:\n",
    "#    *** snapshots[snapshot_index, from 0 to len(snapshot)-1] ***\n",
    "#\n",
    "# 2) What do you want?\n",
    "#    A) Number of particles:\n",
    "#       *** snapshot[snapshot_index][0] ***\n",
    "#       Note that snapshot[snapshot_index][0] can't be subscripted anymore\n",
    "#\n",
    "#    B) Time stamp: \n",
    "#       *** snapshot[snapshot_index][1] ***\n",
    "#       Note that snapshot[snapshot_index][1] can't be subscripted anymore\n",
    "#\n",
    "#    C) Particles masses, positions and velocities:\n",
    "#       *** snapshot[snapshot_index][2] ***\n",
    "#       This is a list of lists (see read_input() for details)\n",
    "#\n",
    "# 3) Which particle are you interested in?\n",
    "#    *** snapshot[snapshot_index][2][particle_index, from 0 to N-1] ***\n",
    "#\n",
    "# 4) What do you want to know about the particle:\n",
    "#    *** Mass: snapshot[snapshot_index][2][particle_index][0] ***\n",
    "#    *** x, y, z: snapshot[snapshot_index][2][particle_index][1, 2, 3] ***\n",
    "#    *** vx, vy, vz: snapshot[snapshot_index][2][particle_index][1+3, 2+3, 3+3] ***\n",
    "def read_snapshots_nbodysh1(input_file_path, output_file_path):\n",
    "    snapshot_0 = read_input_nbodysh1(input_file_path)\n",
    "    snapshots = read_output_nbodysh1(output_file_path)\n",
    "\n",
    "    # Append the intial snapshot to the beginning of the list\n",
    "    snapshots = [snapshot_0] + snapshots\n",
    "\n",
    "    return snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT READING FUNCTIONS (TREECODE)\n",
    "\n",
    "#---------------------------------------------\n",
    "# Input and output files for the treecode program are different than those for nbody_sh1\n",
    "# Nevertheless the output of the reading functions have the same shape of those for the nbody_sh1\n",
    "# There are just small variations depending on the parameters: include_ndim and contains_pot\n",
    "# Read the explanations for the details. Refer to nbody_sh1 i/o functions for reference about\n",
    "# how 'snapshots' works\n",
    "\n",
    "#---------------------------------------------\n",
    "# read_input_treecode() is just for completeness since the treecode program appends\n",
    "# the initial snapshot at the beginning of the output file, as opposed to the nbody_sh1 program\n",
    "# Read it for reference for read_output_treecode()\n",
    "# Input file is structured as follow:\n",
    "#\n",
    "# N\n",
    "# n_dim\n",
    "# t_0\n",
    "# m_1\n",
    "# ..\n",
    "# m_N\n",
    "# x_1, y_1, z_1\n",
    "# ...\n",
    "# x_N, y_N, z_N\n",
    "# vx_1, vy_1, vz_1\n",
    "# ...\n",
    "# vx_N, vy_N, vz_N\n",
    "def read_input_treecode(input_file_path, include_ndim=False):\n",
    "    input_file = open(input_file_path)\n",
    "\n",
    "    # readline() reads the first line and returns it as a string\n",
    "    N = int(input_file.readline())\n",
    "    n_dim = int(input_file.readline())\n",
    "    t_0 = float(input_file.readline())\n",
    "\n",
    "    masses = []\n",
    "    positions = []\n",
    "    velocities = []\n",
    "\n",
    "    # Works like this: data[quantity][particle]\n",
    "    data = [masses, positions, velocities]\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(N):\n",
    "                data[i].append(input_file.readline())\n",
    "                # split() splits a string based on a separator (default is ' ') and returns a list of strings\n",
    "                data[i][j] = data[i][j].split()\n",
    "                # Convert the elements of each splitted string into numbers\n",
    "                for k in range(len(data[i][j])):\n",
    "                    data[i][j][k] = float(data[i][j][k])\n",
    "\n",
    "    # At this point 'data' works like this: data[quantity][particle_index][quantity_index]\n",
    "    #                                       quantity: 0, 1, 2 (mass, positions, velocities)\n",
    "    #                                       particle: 0, 1, 2, ..., N-1\n",
    "    #                                       quantity_index: just 0 if quantity = 0\n",
    "    #                                                       0, 1, 2 (x, y, z) if quantity = 1\n",
    "    #                                                       0, 1, 2 (vx, vy, vz) if quantity = 2\n",
    "    input_file.close()\n",
    "\n",
    "    # Populate 'particles_0' by cycling over 'data'\n",
    "    particles_0 = []\n",
    "\n",
    "    for j in range(N):\n",
    "        particle_0 = []\n",
    "        for i in range(3):\n",
    "            for k in range(len(data[i][j])):\n",
    "                particle_0.append(data[i][j][k])\n",
    "        particles_0.append(particle_0)\n",
    "\n",
    "    # Wether to include n_dim in the snapshot or not\n",
    "    if include_ndim:\n",
    "        snapshot_0 = [N, t_0, particles_0, n_dim]\n",
    "    else:\n",
    "        snapshot_0 = [N, t_0, particles_0]\n",
    "\n",
    "    return snapshot_0\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Read the output file:\n",
    "# Output file is structured like the input file, but for the fact the structure\n",
    "# is repeated for every time.\n",
    "# See read_input() for details\n",
    "# Returns a list of snapshot of the evolved system (t>t_0)\n",
    "# If contains_pot=True then to each particle also its potential energy is attached at index 7\n",
    "def read_output_treecode(output_file_path, include_ndim=False, contains_pot=True):\n",
    "    output_file = open(output_file_path)\n",
    "\n",
    "    # List to store all the snapshots in the output file\n",
    "    snapshots = []\n",
    "\n",
    "    # Try except here detects the EOF\n",
    "    # int() throws an exception when tries to convert something different than a number\n",
    "    while True:\n",
    "        try:\n",
    "            N = int(output_file.readline())\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        # LIKE read_input() START\n",
    "        \n",
    "        n_dim = int(output_file.readline())\n",
    "        t_stamp = float(output_file.readline())\n",
    "\n",
    "        masses = []\n",
    "        positions = []\n",
    "        velocities = []\n",
    "        potentials = []\n",
    "\n",
    "        if contains_pot:\n",
    "            data = [masses, positions, velocities, potentials]\n",
    "        else:\n",
    "            data = [masses, positions, velocities]\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            for j in range(N):\n",
    "                    data[i].append(output_file.readline())\n",
    "                    data[i][j] = data[i][j].split()\n",
    "                    for k in range(len(data[i][j])):\n",
    "                        data[i][j][k] = float(data[i][j][k])\n",
    "        \n",
    "        particles = []\n",
    "\n",
    "        for j in range(N):\n",
    "            particle = []\n",
    "            for i in range(len(data)):\n",
    "                for k in range(len(data[i][j])):\n",
    "                    particle.append(data[i][j][k])\n",
    "            particles.append(particle)\n",
    "\n",
    "        # LIKE read_input() END\n",
    "        \n",
    "        # Append the snapshot [N, t_stamp, particles] to the snapshots list\n",
    "        if include_ndim:\n",
    "            snapshots.append([N, t_stamp, particles, n_dim])\n",
    "        else:\n",
    "            snapshots.append([N, t_stamp, particles])\n",
    "\n",
    "    output_file.close()\n",
    "    \n",
    "    return snapshots\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# SEE read_output() for when potential energy is given in the file\n",
    "def read_snapshots_treecode(input_file_path, output_file_path, include_ndim=False):\n",
    "    snapshot_0 = read_input_treecode(input_file_path, include_ndim)\n",
    "    snapshots = read_output_treecode(output_file_path, include_ndim)\n",
    "\n",
    "    # Append the intial snapshot to the beginning of the list\n",
    "    snapshots = [snapshot_0] + snapshots\n",
    "\n",
    "    return snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATHEMATICAL FUNCTIONS\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Returns the difference between two vectors (vector_2 - vector_1)\n",
    "# \n",
    "# If vectors are positions:\n",
    "# It is a vector that points from position_1 to position_2: [x_2 - x_1, y_2 - y_1, z_2 - z_1]\n",
    "# \n",
    "# If vectors are velocities:\n",
    "# It is a vectors that describes the relative velocity in the frame in which particle 1 is at rest\n",
    "# [vx_2 - vx_1, vy_2 - vy_1, vz_2 - vz_1]\n",
    "#\n",
    "# Imput parameters should be strictly numpy arrays of 3 numbers: (x, y, z)\n",
    "def compute_vector_diff(vector_1, vector_2):\n",
    "    return vector_2 - vector_1\n",
    "\n",
    "# Returns the vectorial product of two vectors\n",
    "# Imput parameters are strictly numpy arrays of 3 numbers: (x, y, z)\n",
    "#\n",
    "# Use NP.CROSS() for a safe and complete implementation\n",
    "def compute_vectorial_product(vector_1, vector_2):\n",
    "    x = vector_1[1] * vector_2[2] - vector_1[2] * vector_2[1]\n",
    "    y = vector_1[2] * vector_2[0] - vector_1[0] * vector_2[2]\n",
    "    z = vector_1[0] * vector_2[1] - vector_1[1] * vector_2[0]\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Returns the absolute value of a vector to the absval-th power\n",
    "def compute_vector_abs(vector, absval=1):\n",
    "    value = 0\n",
    "\n",
    "    for i in range(len(vector)):\n",
    "        value += vector[i] ** 2\n",
    "    \n",
    "    # Don't waste computational power if you want the square of the vector\n",
    "    if absval == 2:\n",
    "        pass\n",
    "    else:\n",
    "        value = value ** (absval / 2)\n",
    "\n",
    "    return value\n",
    "\n",
    "# Returns the distance between two points\n",
    "# Imput parameters are arrays of 3 numbers: (x, y, z)\n",
    "def compute_distance(point_1, point_2):\n",
    "    distance = 0\n",
    "    for i in range (3):\n",
    "        distance += (point_1[i] - point_2[i]) ** 2\n",
    "    \n",
    "    return distance ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COORDINATES FUNCTIONS\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Returns the 3D vector (x, y, z) correspoding to the spherical_coordinates (r, theta, phi)\n",
    "# Imput parameter is strictly a numpy array of 3 numbers: (r, theta, phi)\n",
    "def spherical_to_cartesian(spherical_coordinates):\n",
    "    r = spherical_coordinates[0]\n",
    "    theta = spherical_coordinates[1]\n",
    "    phi = spherical_coordinates[2]\n",
    "\n",
    "    x = r * np.sin(theta) * np.cos(phi)\n",
    "    y = r * np.sin(theta) * np.sin(phi)\n",
    "    z = r * np.cos(theta)\n",
    "\n",
    "    # Floating point precision would not give exact results around zeros of goniometric functions\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Returns the 3D vector (r, theta, phi) correspoding to the cartesian_coordinates (x, y, z)\n",
    "# Imput parameter is strictly a numpy array of 3 numbers: (x, y, z)\n",
    "def cartesian_to_spherical(cartesian_coordinates):\n",
    "    x = cartesian_coordinates[0]\n",
    "    y = cartesian_coordinates[1]\n",
    "    z = cartesian_coordinates[2]\n",
    "\n",
    "    r = ((x ** 2) + (y ** 2) + (z ** 2)) ** (1 / 2)\n",
    "\n",
    "    if x == 0 and y == 0 and z == 0:\n",
    "        theta = None\n",
    "    else:\n",
    "        theta = np.arccos(z / r)\n",
    "\n",
    "    if x == 0 and y == 0:\n",
    "        phi = None\n",
    "    else:\n",
    "        phi = np.arccos(x / (r * np.sin(theta)))\n",
    "        if y < 0:\n",
    "            phi = 2 * np.pi - phi\n",
    "    \n",
    "    # Floating point precision would not give exact results around zeros of goniometric functions\n",
    "    return np.array([r, theta, phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNAPSHOTS READING FUNCTIONS & SMALL CALCULATIONS\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# Reads an 'indexes' parameter and converts it into a numpy array\n",
    "# 'indexes' can be an integer, a numpy array (of specified indexes) or 'all'\n",
    "# If indexes='all', also 'all_number' must be specified; it is the lenght of\n",
    "# the list of all indexes. It must be > 0\n",
    "# Returns a numpy array containing the required indexes\n",
    "def indexes_par_reader(indexes, all_number=None):\n",
    "    # If indexes = 'all', get all indexes\n",
    "    if (type(indexes) == str and indexes == 'all' and\n",
    "        (type(all_number) == int or type(all_number) == np.int_) and all_number > 0):\n",
    "        _indx = np.array(range(all_number))\n",
    "\n",
    "    # If 'indexes' is an integer, make an array of one element containing it\n",
    "    elif type(indexes) == int or type(indexes) == np.int_:\n",
    "        _indx = np.array([indexes])\n",
    "    \n",
    "    # If 'indexes' is already a 1 dimension numpy array, return it as it is\n",
    "    elif (type(indexes) == np.ndarray) and (indexes.ndim == 1):\n",
    "        _indx = np.copy(indexes)\n",
    "\n",
    "    return _indx\n",
    "    \n",
    "# Returns an array of the number of particles of the snapshots\n",
    "def get_N(snapshots):\n",
    "    return np.array([snapshots[i][0] for i in range(len(snapshots))])\n",
    "\n",
    "# Returns an array of the time stamps of the snapshots\n",
    "def get_timestamps(snapshots):\n",
    "    return np.array([snapshots[i][1] for i in range(len(snapshots))])\n",
    "\n",
    "# Returns an array of the specified masses at the specified times\n",
    "# If total=True returns the total mass\n",
    "# particle_indexs are the indexes of the masses to consider\n",
    "# time_indexes are the indexes of the snapshot times to consider\n",
    "# They can be numpy arrays, single integer values or 'all'\n",
    "#\n",
    "# *** WARNINGS ***\n",
    "#\n",
    "# See *** WARNINGS *** in get_3d_vec()\n",
    "def get_masses(snapshots, particle_indexes, total=False, time_indexes=0):\n",
    "    # See get_3d_vec() for explanation\n",
    "    T_indx = indexes_par_reader(time_indexes, len(snapshots))\n",
    "\n",
    "    if type(time_indexes) == int or type(time_indexes) == np.int_:\n",
    "        P_indx = indexes_par_reader(particle_indexes, len(snapshots[time_indexes][2]))\n",
    "    else:\n",
    "        P_indx = indexes_par_reader(particle_indexes, snapshots[0][0])\n",
    "\n",
    "    masses = np.zeros((len(T_indx), len(P_indx)))\n",
    "\n",
    "    for r_t_i, time_index in zip(range(len(T_indx)), T_indx):\n",
    "        for r_p_i, particle_index in zip(range(len(P_indx)), P_indx):\n",
    "            masses[r_t_i][r_p_i] = snapshots[time_index][2][particle_index][0]\n",
    "        if total:\n",
    "            masses[r_t_i] = np.sum(masses[r_t_i])\n",
    "\n",
    "    if total:\n",
    "        masses = np.delete(masses, slice(1, len(P_indx)), axis=1)\n",
    "\n",
    "    if masses.shape == (1, 1):\n",
    "        return masses[0][0]\n",
    "    else:\n",
    "        return np.squeeze(masses)\n",
    "\n",
    "# Compute the position or velocity of the center of mass for the specified times\n",
    "# Returns an array with shape: [[qt_x, qt_y, qt_z]_ti_0, ..., [qt_x, qt_y, qt_z]_ti_(len(time_indexes)-1)]\n",
    "# vec = 'pos', 'vel'\n",
    "# time_indexes are the indexes of the snapshot that will be taken into account\n",
    "# particle_indexs are the indexes of the masses to consider\n",
    "# They can be numpy arrays, single integer values or 'all'\n",
    "#\n",
    "# use_stored: whether to use the saved values or not\n",
    "# save: wheter to save the computed results or not\n",
    "# If the file exists and both 'use_stored' and 'save' are set to True, then\n",
    "# the results are read but they won't get resaved\n",
    "#\n",
    "# *** WARNINGS ***\n",
    "#\n",
    "# See *** WARNINGS *** in get_3d_vec()\n",
    "def get_center_of_mass(snapshots, time_indexes, vec='', particle_indexes='all', use_stored=True, save=False):\n",
    "    # See get_3d_vec() for explanation\n",
    "    files_dir_path = 'data_results'\n",
    "    file_name = 'cm_' + vec + '.npy'\n",
    "    file_path = os.path.join(files_dir_path, file_name)\n",
    "\n",
    "    if not use_stored:\n",
    "        T_indx = indexes_par_reader(time_indexes, len(snapshots))\n",
    "\n",
    "        if type(time_indexes) == int or type(time_indexes) == np.int_:\n",
    "            P_indx = indexes_par_reader(particle_indexes, len(snapshots[time_indexes][2]))\n",
    "        else:\n",
    "            P_indx = indexes_par_reader(particle_indexes, snapshots[0][0])\n",
    "        \n",
    "        M_tot = get_masses(snapshots, particle_indexes=P_indx, total=True, time_indexes=T_indx)\n",
    "        if type(M_tot) == np.float_:\n",
    "            M_tot = np.array([M_tot])\n",
    "        \n",
    "        if vec.lower() == 'pos':\n",
    "            shift = 0\n",
    "        elif vec.lower() == 'vel':\n",
    "            shift = 3\n",
    "\n",
    "        qt_CM = np.zeros((len(T_indx), 3))\n",
    "\n",
    "        for r_t_i, time_index in zip(range(len(T_indx)), T_indx):\n",
    "            for coordinate_index in range(3):\n",
    "                for particle_index in P_indx:\n",
    "                    qt_CM[r_t_i][coordinate_index] += (snapshots[time_index][2][particle_index][0] *\n",
    "                                                    snapshots[time_index][2][particle_index][1+\n",
    "                                                                                                coordinate_index+\n",
    "                                                                                                shift])\n",
    "                qt_CM[r_t_i][coordinate_index] /= M_tot[r_t_i]\n",
    "        \n",
    "        if save:\n",
    "            os.makedirs(files_dir_path, exist_ok=True)\n",
    "            np.save(file_path, qt_CM)\n",
    "    else:\n",
    "        if os.path.isfile(file_path):\n",
    "            qt_CM = np.load(file_path)\n",
    "        else:\n",
    "            qt_CM = get_center_of_mass(snapshots, time_indexes, vec, particle_indexes, False, save)\n",
    "\n",
    "    return np.squeeze(qt_CM)\n",
    "\n",
    "# absval = 0: returns an array of 3D vectors of the specified particles, for the specified quantity\n",
    "#             in the specified reference frame\n",
    "# [[Qx_0, Qy_0, Qz_0], [Qx_1, Qy_1, Qz_1], ..., [len(snapshots)-1]]\n",
    "# absval = n != 0: returns the absolute value of the vectors to the absval-th power\n",
    "# vec = 'pos', 'vel'\n",
    "# rf = 'snapshot', 'cm' (center of mass), 'particle', 'absolute';\n",
    "# if particle rf_arg is a particle index\n",
    "# if 'absolute' rf_arg is a fixed point in space to be specified using an array of shape (3,)\n",
    "# particle_indexes and time_indexes are the indexes of the snapshot that will be taken into account\n",
    "# They can be numpy arrays, single integer values or 'all'\n",
    "#\n",
    "# *** WARNINGS ***\n",
    "#\n",
    "# It is reccomended to use the 'indexes' parameters to get the desired values because it is\n",
    "# more efficient in this implementation than doing more function calls\n",
    "#\n",
    "# 'indexs' parameters MUST BE NUMPY ARRAYS\n",
    "# \n",
    "# In order to use the indexes parameters as arrays, is required for the snapshot parameter\n",
    "# to be homogneous in shape between axis 0 and axis 2, i.e.  the number of particles\n",
    "# in the snapshot should be the same at every time\n",
    "# If this condition is not satisfied, runtime errors might occour\n",
    "def get_3D_vec(snapshots, particle_indexes, vec='', absval=0, rf='snapshot',\n",
    "               rf_arg=None, time_indexes='all'):\n",
    "    if vec.lower() == 'pos':\n",
    "        shift = 0\n",
    "    elif vec.lower() == 'vel':\n",
    "        shift = 3\n",
    "    \n",
    "    # Convert the 'indexes' parameters into numpy arrays\n",
    "    # See indexes_par_reader() for details\n",
    "    T_indx = indexes_par_reader(time_indexes, len(snapshots))\n",
    "\n",
    "    # The following 'if' statement is to allow the function to work even if\n",
    "    # an inhomogeneous snapshot is passed as a parameter (see above for details)\n",
    "    # If that is the case, this should garantee the result at least when integers paramters\n",
    "    # are passed to the 'indexes' parameters\n",
    "    if type(time_indexes) == int or type(time_indexes) == np.int_:\n",
    "        P_indx = indexes_par_reader(particle_indexes, len(snapshots[time_indexes][2]))\n",
    "    else:\n",
    "        P_indx = indexes_par_reader(particle_indexes, snapshots[0][0])\n",
    "\n",
    "    # Initialise the result\n",
    "    result = np.zeros((len(P_indx), len(T_indx), 3))\n",
    "\n",
    "    # If required, compute the center of mass at the specified times using all the masses\n",
    "    if rf.lower() == 'cm':\n",
    "        # Try to use stored value if possible\n",
    "        cm_vec = get_center_of_mass(snapshots, T_indx, vec, particle_indexes='all')\n",
    "        if len(T_indx) == len(snapshots): # Happens if 'time_indexes' = 'all' or successfully read from file\n",
    "            pass\n",
    "        elif len(T_indx) != len(cm_vec): # Happens if you read from file and 'time_indexes' != 'all\n",
    "            cm_vec = cm_vec[T_indx] # Extract the wanted indexes\n",
    "\n",
    "        # if len(T_indx) == len(snapshots):\n",
    "        #     cm_vec = get_center_of_mass(snapshots, T_indx, vec, particle_indexes='all', use_stored=True)\n",
    "        # else:\n",
    "        #     cm_vec = get_center_of_mass(snapshots, T_indx, vec, particle_indexes='all', use_stored=False)\n",
    "\n",
    "    for r_p_i, particle_index in zip(range(len(P_indx)), P_indx):\n",
    "        # Compute in the snapshot reference frame\n",
    "        if rf.lower() == 'snapshot':\n",
    "            for r_t_i, time_index in zip(range(len(T_indx)), T_indx):\n",
    "                result[r_p_i][r_t_i] = snapshots[time_index][2][particle_index][1+shift:4+shift]\n",
    "\n",
    "        # Compute in the center of mass reference frame\n",
    "        elif rf.lower() == 'cm':\n",
    "            particle_vec = np.array([snapshots[time_index][2][particle_index][1+shift:4+shift]\n",
    "                                     for time_index in T_indx])\n",
    "            result[r_p_i] = compute_vector_diff(cm_vec, particle_vec)\n",
    "\n",
    "        # Compute in the reference frame of the specified particle\n",
    "        elif rf.lower() == 'particle':\n",
    "            rf_arg_vec = np.array([snapshots[time_index][2][rf_arg][1+shift:4+shift]\n",
    "                                        for time_index in T_indx])\n",
    "            particle_vec = np.array([snapshots[time_index][2][particle_index][1+shift:4+shift]\n",
    "                                     for time_index in T_indx])\n",
    "            result[r_p_i] = compute_vector_diff(rf_arg_vec, particle_vec)\n",
    "\n",
    "        elif rf.lower() == 'absolute':\n",
    "            rf_arg_vec = np.array([rf_arg for time_index in T_indx])\n",
    "            particle_vec = np.array([snapshots[time_index][2][particle_index][1+shift:4+shift]\n",
    "                                     for time_index in T_indx])\n",
    "            result[r_p_i] = compute_vector_diff(rf_arg_vec, particle_vec)\n",
    "    \n",
    "    # Return the result as it is\n",
    "    if absval == 0:\n",
    "        pass\n",
    "    \n",
    "    # Compute the absval-th power of every vector into \"result\"\n",
    "    elif absval != 0:\n",
    "        for particle_index in range(len(result)):\n",
    "            for time_index in range(len(result[particle_index])):\n",
    "                result[particle_index][time_index] = compute_vector_abs(result[particle_index][time_index],\n",
    "                                                                        absval)\n",
    "\n",
    "        # Because of how numpy arrays works, we need to slice the array to take the first column\n",
    "        # Actually any column would be fine because now their content is equal\n",
    "        # The point is that we want just one set of values and not three\n",
    "        result = np.delete(result, [1, 2], axis=2)\n",
    "\n",
    "    # Squeeze the array to get rid of the 1-element lists\n",
    "    # Or take the [0][0][0] element if all axis have lenght 1 to avoid a 0 dimensions array\n",
    "    if result.shape == (1, 1, 1):\n",
    "        return result[0][0][0]\n",
    "    else:\n",
    "        return np.squeeze(result)\n",
    "\n",
    "# Returns the potentials of each particle at the specified time\n",
    "# Works only if the overal potential for each particle at every time\n",
    "# is part of 'snapshots'\n",
    "def get_saved_potentials(snapshots, time_index):\n",
    "    return np.array([snapshots[time_index][2][particle_index][7]\n",
    "                     for particle_index in range(snapshots[time_index][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHYSICS FUNCTIONS\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Returns the energy of the system for the specified time in the specified reference frame\n",
    "# E_type = 'kin', 'pot', 'tot', 'all'. If 'all', returns an ordered tuple: (E_kin, E_pot, E_tot)\n",
    "# rf = 'snapshot', 'cm' (center of mass), 'particle', 'absolute' (see get_3d_vec())\n",
    "# E_parts_kin and E_parts_pot are numpy arrays passed to the fucntion that can be modified\n",
    "# This is exactly because they are arrays and the function will read their memory addresses\n",
    "# They will be modified only if they have the right shape: E_parts_kin: (N, )\n",
    "#                                                          E_parts_pot: (N, N); (N, ) if contains_pot=True\n",
    "# Where N is the number of particles\n",
    "# If contains_pot=True then the potential of each particle is read from the snapshot\n",
    "# (index 7 of each particle, after vz)\n",
    "#\n",
    "# *** ABOUT E_parts ***\n",
    "#\n",
    "# E_parts_kin is a collection of the kinetic energies of every particle at the specified time\n",
    "# It works like this: E_parts_kin[particle_index]\n",
    "#\n",
    "# E_parts_pot is a collection of the potential energies of every particle\n",
    "# with all other particles at the specified time\n",
    "# It works like this: E_parts_pot[particle_index][particle_index]\n",
    "# Self energies are set to zero: E_parts_pot[i][j] = 0 if i = j\n",
    "# Note that if you want the total potential energy at a given time you can sum all the contents of \n",
    "# E_parts_pot but you have to divide by 2 at the end because it is a symmetric matrix\n",
    "#\n",
    "# if contains_pot=True, E_parts_pot will work like this: E_parts_pot[particle_index] where this time\n",
    "# each element contains the overall potential energy felt by the specified particle\n",
    "# Summing everything and dividing by 2 gives the potential energy\n",
    "#\n",
    "# I think that further generalisation of this function might be troublesome\n",
    "# and would not lead to tangible advantages\n",
    "def get_energy(snapshots, time_index, E_type='', rf='snapshot', rf_arg=None,\n",
    "               E_parts_kin=None, E_parts_pot=None, contains_pot=False):\n",
    "    N = snapshots[time_index][0]\n",
    "\n",
    "    if E_type.lower() == 'kin':\n",
    "        E = 0\n",
    "        \n",
    "        # An array of the velocities squared of every mass at the specified time\n",
    "        # [v_0_time_index, v_1_time_index, v_2_time_index, ..., v_(N-1)_time_index]\n",
    "        v_squared = get_3D_vec(snapshots, 'all', 'vel', 2, rf, rf_arg, time_indexes=time_index)\n",
    "\n",
    "        for i in range(N):\n",
    "            value = (1 / 2) * snapshots[time_index][2][i][0] * v_squared[i]\n",
    "            E += value\n",
    "\n",
    "            # If requested save the individual kinetic energy\n",
    "            if type(E_parts_kin) == np.ndarray and E_parts_kin.shape == (N, ):\n",
    "                E_parts_kin[i] = value\n",
    "    elif E_type.lower() == 'pot':\n",
    "        E = 0\n",
    "\n",
    "        # If snapshots doesn't contain potentials, compute them\n",
    "        # Depending on the number of particles, this might take a (long) while\n",
    "        if not contains_pot:\n",
    "            # Same as above but it's for position vectors\n",
    "            # positions[i] is the 3D vector of the i-th particle at specified time\n",
    "            #\n",
    "            # Note that since we need just the relative distances between particles, it is not\n",
    "            # necessary to compute the positions in a reference frame different from 'snapshot'\n",
    "            # Infact relative distances are frame independent\n",
    "            # This solution is preferable because more computationally efficient\n",
    "            positions = get_3D_vec(snapshots, 'all', 'pos', rf='snapshot', time_indexes=time_index)\n",
    "\n",
    "            # Cycle over all possible combination of particles\n",
    "            # part_0: part_1, part_2, part_3, ..., part_(N-1)\n",
    "            # part_1: part_2, part_3, part_4, ..., part_(N-1)\n",
    "            # part_2: part_3, part_4, part_5, ..., part_(N-1)\n",
    "            # ...\n",
    "            # part_i: part_(i+1), part_(i+2), ..., part_(N-1)\n",
    "            for i in range(N):\n",
    "                for j in range(i+1, N):\n",
    "                    distance = compute_distance(positions[i], positions[j])\n",
    "                    value = -1 * snapshots[time_index][2][i][0] * snapshots[time_index][2][j][0] / distance\n",
    "                    E += value\n",
    "\n",
    "                    # If requested save the individual potential energy interaction\n",
    "                    # Build up a symmetric matrix\n",
    "                    if type(E_parts_pot) == np.ndarray and E_parts_pot.shape == (N, N):\n",
    "                        E_parts_pot[i][j] = value\n",
    "                        E_parts_pot[j][i] = value\n",
    "\n",
    "        # If snapshots contains potentials, use them instead\n",
    "        # See the explanation in the description above\n",
    "        else:\n",
    "            saved_potentials = get_saved_potentials(snapshots, time_index)\n",
    "            E += np.sum(saved_potentials * get_masses(snapshots, 'all', time_indexes=time_index)) / 2\n",
    "            if type(E_parts_pot) == np.ndarray and E_parts_pot.shape == (N, ):\n",
    "                # copyto() just provides an elegant way to copy array elements into another\n",
    "                # without going through a cycle. We want this because E_parts_pot points to an external array\n",
    "                np.copyto(E_parts_pot, saved_potentials)\n",
    "    elif E_type.lower() == 'tot':\n",
    "        E_kin = get_energy(snapshots, time_index, 'kin', rf, rf_arg,\n",
    "                           E_parts_kin, E_parts_pot, contains_pot)\n",
    "        E_pot = get_energy(snapshots, time_index, 'pot', rf, rf_arg,\n",
    "                           E_parts_kin, E_parts_pot, contains_pot)\n",
    "        E = E_kin + E_pot\n",
    "\n",
    "    elif E_type.lower() == 'all':\n",
    "        E_kin = get_energy(snapshots, time_index, 'kin', rf, rf_arg,\n",
    "                           E_parts_kin, E_parts_pot, contains_pot)\n",
    "        E_pot = get_energy(snapshots, time_index, 'pot', rf, rf_arg,\n",
    "                           E_parts_kin, E_parts_pot, contains_pot)\n",
    "        E = E_kin + E_pot\n",
    "\n",
    "        E = E_kin, E_pot, E\n",
    "\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM SPECIFIC FUNCTIONS\n",
    "\n",
    "#-------------------------------------------------\n",
    "def expected_lagrangian_radius(b, q):\n",
    "    return b / np.sqrt(q ** (-2 / 3) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "#---------------------------------------------\n",
    "b = 45 # Scale radius\n",
    "dyn_time =  9.48349988690498 # Dynamicl time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FILE READING\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "input_file_path = \"treecode_in_mpert100.txt\"\n",
    "output_file_path = \"treecode_out_mpert100.txt\"\n",
    "\n",
    "# The output already includes the initial snapshot\n",
    "snapshots = read_output_treecode(output_file_path, contains_pot=False)\n",
    "print(snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = snapshots[0][0] # Number of particles\n",
    "time_stamp = get_timestamps(snapshots)\n",
    "print(snapshots)\n",
    "\n",
    "# Save the indexes of the perturbers. We know them in advance\n",
    "perturber_indexes = np.array([N-1])\n",
    "print(perturber_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_pos \u001b[38;5;241m=\u001b[39m get_center_of_mass(snapshots, time_indexes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, vec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Distance of the center of mass from (0, 0, 0) at every time\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# cm_pos_radius[time_index]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m cm_pos_radius \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mcompute_vector_abs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtime_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msnapshots\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_pos \u001b[38;5;241m=\u001b[39m get_center_of_mass(snapshots, time_indexes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, vec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Distance of the center of mass from (0, 0, 0) at every time\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# cm_pos_radius[time_index]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m cm_pos_radius \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mcompute_vector_abs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m time_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(snapshots))])\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mcompute_vector_abs\u001b[0;34m(vector, absval)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_vector_abs\u001b[39m(vector, absval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     30\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     33\u001b[0m         value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vector[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Don't waste computational power if you want the square of the vector\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "# \"pos\" works like this: pos[particle_index][time_index][coordinate_index]\n",
    "pos = get_3D_vec(snapshots, 'all', 'pos', rf='snapshot')\n",
    "\n",
    "# \"cm_pos\" works like this: cm_pos[time_index][coordinate_index]\n",
    "cm_pos = get_center_of_mass(snapshots, time_indexes='all', vec='pos', save=True)\n",
    "\n",
    "# Distance of the center of mass from (0, 0, 0) at every time\n",
    "# cm_pos_radius[time_index]\n",
    "cm_pos_radius = np.array([compute_vector_abs(cm_pos[time_index]) for time_index in range(len(snapshots))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm_pos)\n",
    "print(len(snapshots[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"vel\" works like this: vel[particle_index][time_index][coordinate_index]\n",
    "vel = get_3D_vec(snapshots, 'all', 'vel', rf='snapshot')\n",
    "\n",
    "# \"cm_vel\" works like this: cm_vel[time_index][coordinate_index]\n",
    "cm_vel = get_center_of_mass(snapshots, time_indexes='all', vec='vel', save=True)\n",
    "\n",
    "# Velocity of the center of mass at every time\n",
    "# cm_vel_abs[time_index]\n",
    "cm_vel_abs = np.array([compute_vector_abs(cm_vel[time_index]) for time_index in range(len(snapshots))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENERGY\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Initialize a dictionary for the energy\n",
    "# Each key, 'kin', 'pot', 'tot', will contain an array of values describing the corresponding\n",
    "# energy for every time stamp. Example: Energy['kin'] = [E_kin_0, E_kin_1, ..., E_kin_(len(snapshot)-1)]\n",
    "Energy = {}\n",
    "Energy_keys = ['kin', 'pot', 'tot']\n",
    "\n",
    "# Initialise correctly shaped arrays to store the individual values\n",
    "# of the kinetic and potential energy during the calculation\n",
    "# Their time axes (axes 0) entries will be modified by get_energy() when passed as parameters\n",
    "# See get_energy() for details\n",
    "\n",
    "# It works likw this: particles_E_kin[time_index][particle_index]\n",
    "particles_E_kin = np.zeros((len(snapshots), N))\n",
    "# It works likw this: particles_E_pot[time_index][particle_index]\n",
    "particles_E_pot = np.zeros((len(snapshots), N))\n",
    "\n",
    "# Get all the energies for every snapshot. See get_energy() for details.\n",
    "# \"en\" works like this: en[time_index][energy_type], where energy_type = 0, 1, 2 ('kin', 'pot', 'tot')\n",
    "#\n",
    "# *** WARNING ***\n",
    "#\n",
    "# Be aware of the fact that setting contains_pot=False changes the required shape\n",
    "# of particles_e_pot and hence would affect subsequent parts of the notebook that uses it\n",
    "en = np.array([get_energy(snapshots, time_index, 'all', rf='cm',\n",
    "                          E_parts_kin=particles_E_kin[time_index],\n",
    "                          E_parts_pot=particles_E_pot[time_index],\n",
    "                          contains_pot=True)\n",
    "                          for time_index in tqdm(range(len(snapshots)))])\n",
    "\n",
    "# Swap the axis to obtain en[energy_type][time_index]\n",
    "# So writing en[0] will return an array containing the kinetic energy of the system at every time\n",
    "en = np.swapaxes(en, 0, 1)\n",
    "\n",
    "# Store the results in the dictionary\n",
    "Energy['kin'] = en[0]\n",
    "Energy['pot'] = en[1]\n",
    "Energy['tot'] = en[2]\n",
    "\n",
    "del en # This is not needed\n",
    "\n",
    "# Compute the relative energy error\n",
    "Energy_rel_e = (Energy['tot'] - Energy['tot'][0]) / Energy['tot'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list to store the generated figures \n",
    "figures = []\n",
    "\n",
    "# Initialise a list to store their names\n",
    "figures_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENERGY PLOTS\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# These are ordered to match the Energy_keys\n",
    "title_labels = [\"Kinetic Energy\", \"Potential Energy\", \"Total Energy\"]\n",
    "\n",
    "n_rows = 2\n",
    "n_col = 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_col, figsize=(20, 15), sharex=True)\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_col):\n",
    "        axes[i][j].tick_params(labelsize=12)\n",
    "        axes[i][j].tick_params(axis='x', length=10, direction='inout')\n",
    "\n",
    "        axes[i][j].xaxis.set_major_locator(ticker.FixedLocator([0] +\n",
    "                                                               [dyn_time * i\n",
    "                                                                for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "        axes[i][j].xaxis.set_major_formatter(ticker.FixedFormatter([0] +\n",
    "                                                                   [r'${i}t_{{\\text{{dyn}}}}$'.format(i=i)\n",
    "                                                                    for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "\n",
    "        axes[i][j].xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "        axes[i][j].xaxis.set_minor_formatter(ticker.NullFormatter())\n",
    "\n",
    "index = 0 # Index to count cycles and break\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_col):\n",
    "        axes[i][j].set_title(title_labels[index], size=18)\n",
    "\n",
    "        axes[i][j].plot(time_stamp, Energy[Energy_keys[index]])\n",
    "\n",
    "        index +=1\n",
    "        if index == 3:\n",
    "            break\n",
    "\n",
    "axes[1][1].set_title(\"Relative Energy Error\", size=18)\n",
    "\n",
    "axes[1][1].set_ylabel(r\"$(E_{tot}-E_{init})/E_{init}$\", size=15)\n",
    "\n",
    "axes[1][1].yaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "\n",
    "axes[1][1].plot(time_stamp, Energy_rel_e)\n",
    "\n",
    "figures.append(fig)\n",
    "figures_names.append(\"energy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTICLES INSIDE LAGRANGIAN RADII\n",
    "\n",
    "#------------------------------------------------------\n",
    "# We want to count how many particles stay inside some lagrangian radii\n",
    "# particle_distance_cm works like this: particle_distance_cm[particle_index][time_index]\n",
    "particles_distance_cm = get_3D_vec(snapshots, 'all', 'pos', absval=1, rf='cm')\n",
    "\n",
    "# Swap the axis in order to have particle_distance_cm[time_index][particle_index]\n",
    "particles_distance_cm = np.swapaxes(particles_distance_cm, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some lagrangian_radii using quantiles to be applied to the radii distribution\n",
    "# We can do this because our particles have the same mass\n",
    "lagrangian_radii_frac = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "# Compute the lagrangian radii at every time\n",
    "# lagrangian_radii[r_index][time_index]\n",
    "lagrangian_radii = np.quantile(particles_distance_cm, lagrangian_radii_frac, axis=1)\n",
    "\n",
    "# Compute the time average of the lagrangian radii at every time\n",
    "# mean_lagrangian_radii[r_index]\n",
    "mean_lagrangian_radii = np.mean(lagrangian_radii, axis=1)\n",
    "\n",
    "# Compute the expected lagrangian radii\n",
    "expected_lagrangian_radii = [expected_lagrangian_radius(b=b, q=lagrangian_radii_frac[i])\n",
    "                             for i in range(len(lagrangian_radii_frac))]\n",
    "\n",
    "# Make colors of the lagrangian_radii. Use indexes to access them\n",
    "# lr_colors[r_index]\n",
    "lr_colors = plt.colormaps.get_cmap('gist_rainbow')(np.linspace(0, 1, len(lagrangian_radii_frac)))\n",
    "# lr_colors = plt.cm.rainbow(np.linspace(0, 1, len(lagrangian_radii_frac)))\n",
    "\n",
    "# Make labels for the lagrangian radii\n",
    "lr_labels = [r'$R_{{L}}(q={0})$'.format(lagrangian_radii_frac[i])\n",
    "             for i in range(len(lagrangian_radii_frac))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask that tells if, at any time, any particle is inside any lagrangian radius\n",
    "# is_particle_inside_lagra_radii[r_index][time_index][particle_index]\n",
    "is_particle_inside_lagra_radii = np.array([particles_distance_cm <= mean_lagrangian_radii[i]\n",
    "                                           for i in range(len(mean_lagrangian_radii))])\n",
    "\n",
    "# Count how many particles are inside the lagrangian radii at any time\n",
    "# particles_inside_lagra_radii[r_index][time_index]\n",
    "particles_inside_lagra_radii = np.array([np.sum(is_particle_inside_lagra_radii[i], axis=1)\n",
    "                                         for i in range(len(mean_lagrangian_radii))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "fig.suptitle('Lagrangian radii', size=20)\n",
    "\n",
    "# Add a gridspec to the figure\n",
    "gridspec = fig.add_gridspec(2, 2)\n",
    "\n",
    "# Make subfigures inside the original figure at each gridspec position\n",
    "subfigs = [fig.add_subfigure(gs) for gs in gridspec]\n",
    "\n",
    "# Make axis and plot data\n",
    "for sf, i in zip(subfigs, range(len(lagrangian_radii_frac))):\n",
    "    axes = sf.subplots(2, 1, sharex=True)\n",
    "\n",
    "    # Styling\n",
    "    sf.suptitle(lr_labels[i], size=18)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.tick_params(axis='x', length=10, direction='inout')\n",
    "\n",
    "    axes[0].xaxis.set_major_locator(ticker.FixedLocator([0] +\n",
    "                                                        [dyn_time * i\n",
    "                                                         for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "    axes[0].xaxis.set_major_formatter(ticker.FixedFormatter([0] +\n",
    "                                                            [r'${i}t_{{\\text{{dyn}}}}$'.format(i=i)\n",
    "                                                             for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "\n",
    "    axes[0].xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    axes[0].xaxis.set_minor_formatter(ticker.NullFormatter())\n",
    "\n",
    "    axes[0].set_ylabel(r'$R_L$', size=15)\n",
    "    axes[1].set_ylabel(r'$M(R_L)$', size=15)\n",
    "\n",
    "    # Radii\n",
    "    axes[0].plot(time_stamp,\n",
    "                 lagrangian_radii[i],\n",
    "                 label=lr_labels[i], color=lr_colors[i])\n",
    "    axes[0].axhline(mean_lagrangian_radii[i],\n",
    "                    linestyle='--', color=lr_colors[i], label=r'$\\overline{R_L}$')\n",
    "    axes[0].axhline(expected_lagrangian_radii[i],\n",
    "                    linestyle=':', color=lr_colors[i], label=r'$R_L^{\\text{true}}$')\n",
    "\n",
    "    axes[0].axvline(time_stamp[np.argmax(lagrangian_radii[i])],\n",
    "                    color='black', linestyle='-.')\n",
    "\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Masses inside radii\n",
    "    masses_inside_lr = particles_inside_lagra_radii[i] * snapshots[0][2][0][0]\n",
    "    axes[1].plot(time_stamp, masses_inside_lr,\n",
    "                 label=lr_labels[i], color=lr_colors[i])\n",
    "\n",
    "    axes[1].axvline(time_stamp[np.argmin(particles_inside_lagra_radii[i])],\n",
    "                    color='black', linestyle='-.')\n",
    "\n",
    "figures.append(fig)\n",
    "figures_names.append(\"lag_rad_1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "fig.suptitle('Lagrangian radii variation', size=20)\n",
    "\n",
    "# Add a gridspec to the figure\n",
    "gridspec = fig.add_gridspec(2, 2)\n",
    "\n",
    "# Make subfigures inside the original figure at each gridspec position\n",
    "subfigs = [fig.add_subfigure(gs) for gs in gridspec]\n",
    "\n",
    "# Make axis and plot data\n",
    "for sf, i in zip(subfigs, range(len(lagrangian_radii_frac))):\n",
    "    axes = sf.subplots(2, 1, sharex=True)\n",
    "\n",
    "    # Styling\n",
    "    sf.suptitle(lr_labels[i], size=18)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.tick_params(axis='x', length=10, direction='inout')\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "\n",
    "    axes[0].xaxis.set_major_locator(ticker.FixedLocator([0] +\n",
    "                                                        [dyn_time * i\n",
    "                                                         for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "    axes[0].xaxis.set_major_formatter(ticker.FixedFormatter([0] +\n",
    "                                                            [r'${i}t_{{\\text{{dyn}}}}$'.format(i=i)\n",
    "                                                             for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "\n",
    "    axes[0].xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    axes[0].xaxis.set_minor_formatter(ticker.NullFormatter())\n",
    "\n",
    "    axes[0].set_ylabel(r'$\\Delta R_L / R_L^i$', size=15)\n",
    "    axes[1].set_ylabel(r'$\\Delta M(R_L) / M(R_L^i)$', size=15)\n",
    "\n",
    "    # Radii\n",
    "    axes[0].plot(time_stamp,\n",
    "                 (lagrangian_radii[i] - lagrangian_radii[i][0]) / lagrangian_radii[i][0],\n",
    "                 label=lr_labels[i], color=lr_colors[i])\n",
    "    \n",
    "    axes[0].axhline(0, linestyle='--', color=lr_colors[i])\n",
    "\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Masses inside radii\n",
    "    masses_inside_lr = particles_inside_lagra_radii[i] * snapshots[0][2][0][0]\n",
    "    axes[1].plot(time_stamp, (masses_inside_lr - masses_inside_lr[0]) / masses_inside_lr[0],\n",
    "                 label=lr_labels[i], color=lr_colors[i])\n",
    "    \n",
    "    axes[0].axhline(0, linestyle='--', color=lr_colors[i])\n",
    "\n",
    "figures.append(fig)\n",
    "figures_names.append(\"lag_rad_2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "fig.suptitle('Lagrangian radii derivatives', size=20)\n",
    "\n",
    "# Add a gridspec to the figure\n",
    "gridspec = fig.add_gridspec(2, 2)\n",
    "\n",
    "# Make subfigures inside the original figure at each gridspec position\n",
    "subfigs = [fig.add_subfigure(gs) for gs in gridspec]\n",
    "\n",
    "# Make axis and plot data\n",
    "for sf, i in zip(subfigs, range(len(lagrangian_radii_frac))):\n",
    "    axes = sf.subplots(2, 1, sharex=True)\n",
    "\n",
    "    # Styling\n",
    "    sf.suptitle(lr_labels[i], size=18)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.tick_params(labelsize=12)\n",
    "\n",
    "    # Zoom in\n",
    "    # Don't need to limit also axes[1] because x axis is shared\n",
    "    axes[0].set_xlim(np.quantile(time_stamp, [0.45, 0.55]))\n",
    "\n",
    "    axes[0].set_ylabel(r'$\\partial R_L / \\partial t$', size=15)\n",
    "    axes[1].set_ylabel(r'$\\partial M(R_L) / \\partial t$', size=15)\n",
    "\n",
    "    # Radii derivative\n",
    "    lr_der = np.gradient(lagrangian_radii[i], time_stamp)\n",
    "    # lr_der = np.diff(lagrangian_radii[i]) / np.diff(time_stamp)\n",
    "    axes[0].plot(time_stamp, lr_der, color='royalblue')\n",
    "\n",
    "    # Masses inside radii derivative\n",
    "    M_der = np.gradient(particles_inside_lagra_radii[i], time_stamp)\n",
    "    axes[1].plot(time_stamp, M_der, color='crimson')\n",
    "\n",
    "figures.append(fig)\n",
    "figures_names.append(\"lag_rad_3\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "fig.suptitle('Center of mass', size=20)\n",
    "\n",
    "# Make subplots\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(224, sharex=ax2)\n",
    "\n",
    "# Hide ax2 labels\n",
    "for lb in ax2.get_xticklabels():\n",
    "    lb.set_visible(False)\n",
    "\n",
    "ax1.set_title(r\"CM distance from $(0, 0, 0)$\", size=18)\n",
    "ax1.set_ylabel(r'$R_{\\text{CM}}$', size=15)\n",
    "\n",
    "ax2.set_title(\"CM radial velocity\", size=18)\n",
    "ax2.set_ylabel(r'$V_{\\text{CM}}$', size=15)\n",
    "\n",
    "ax3.set_title(\"CM radial velocity variation\", size=18)\n",
    "ax3.set_ylabel(r'$\\Delta V_{\\text{CM}} / V_{\\text{CM}}^i$', size=15)\n",
    "\n",
    "axes = [ax1, ax2, ax3]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.tick_params(axis='x', length=10, direction='inout')\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.FixedLocator([0] +\n",
    "                                                   [dyn_time * i\n",
    "                                                    for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "    ax.xaxis.set_major_formatter(ticker.FixedFormatter([0] +\n",
    "                                                       [r'${i}t_{{\\text{{dyn}}}}$'.format(i=i)\n",
    "                                                        for i in range(1, math.ceil(time_stamp[-1] / dyn_time) + 1)]))\n",
    "\n",
    "    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    ax.xaxis.set_minor_formatter(ticker.NullFormatter())\n",
    "\n",
    "ax3.yaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "\n",
    "ax1.plot(time_stamp, cm_pos_radius, color='slategray')\n",
    "\n",
    "ax2.plot(time_stamp, cm_vel_abs, color='cadetblue')\n",
    "ax3.plot(time_stamp, (cm_vel_abs - cm_vel_abs[0]) / cm_vel_abs[0], color='lightcoral')\n",
    "\n",
    "figures.append(fig)\n",
    "figures_names.append(\"cm\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pert = get_3D_vec(snapshots, perturber_indexes, 'pos', rf='snapshot')\n",
    "vel_pert = get_3D_vec(snapshots, perturber_indexes, 'vel', rf='snapshot')\n",
    "\n",
    "pos_pert_cm = get_3D_vec(snapshots, perturber_indexes, 'pos', rf='cm')\n",
    "vel_pert_cm = get_3D_vec(snapshots, perturber_indexes, 'vel', rf='cm')\n",
    "\n",
    "l_pert = np.cross(pos_pert, vel_pert)\n",
    "l_pert_cm = np.cross(pos_pert_cm, vel_pert_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_labels = [[r'$x$', r'$y$', r'$z$'],\n",
    "               [r'$v_x$', r'$v_y$', r'$v_z$'],\n",
    "               [r'$a_x$', r'$a_y$', r'$a_z$'],\n",
    "               [r'$l_x$', r'$l_y$', r'$l_z$']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16), sharex=True)\n",
    "\n",
    "fig.suptitle(r\"Coordinates; RF: $(0, 0, 0)$\")\n",
    "\n",
    "for ax, i in zip(axes[0], range(len(axes[0]))):\n",
    "    ax.plot(time_stamp, pos_pert[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[0][i])\n",
    "\n",
    "for ax, i in zip(axes[1], range(len(axes[1]))):\n",
    "    ax.plot(time_stamp, vel_pert[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[1][i])\n",
    "\n",
    "for ax, i in zip(axes[2], range(len(axes[2]))):\n",
    "    ax.plot(time_stamp, np.gradient(vel_pert[:, i], time_stamp))\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[2][i])\n",
    "\n",
    "for ax, i in zip(axes[3], range(len(axes[3]))):\n",
    "    ax.plot(time_stamp, l_pert[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[3][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16), sharex=True)\n",
    "\n",
    "fig.suptitle(\"Coordinates; RF: CM\")\n",
    "\n",
    "for ax, i in zip(axes[0], range(len(axes[0]))):\n",
    "    ax.plot(time_stamp, pos_pert_cm[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[0][i])\n",
    "\n",
    "for ax, i in zip(axes[1], range(len(axes[1]))):\n",
    "    ax.plot(time_stamp, vel_pert_cm[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[1][i])\n",
    "\n",
    "for ax, i in zip(axes[2], range(len(axes[2]))):\n",
    "    ax.plot(time_stamp, np.gradient(vel_pert_cm[:, i], time_stamp))\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[2][i])\n",
    "\n",
    "for ax, i in zip(axes[3], range(len(axes[3]))):\n",
    "    ax.plot(time_stamp, l_pert_cm[:, i])\n",
    "    ax.set_xlabel(r'$t$')\n",
    "    ax.set_ylabel(pert_labels[3][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pert_abs = np.array([compute_vector_abs(l_pert[i]) for i in range(len(time_stamp))])\n",
    "l_pert_cm_abs = np.array([compute_vector_abs(l_pert_cm[i]) for i in range(len(time_stamp))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].set_title(\"Angular momentum; RF: (0, 0, 0)\")\n",
    "axes[0].set_xlabel(r'$t$')\n",
    "axes[0].set_ylabel(r'$|l|$')\n",
    "\n",
    "axes[0].plot(time_stamp, l_pert_abs)\n",
    "\n",
    "axes[1].set_title(\"Angular momentum; RF: CM\")\n",
    "axes[1].set_xlabel(r'$t$')\n",
    "axes[1].set_ylabel(r'$|l|$')\n",
    "axes[1].plot(time_stamp, l_pert_cm_abs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE SAVER\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# Toggle on/off the image saver\n",
    "save_images = False\n",
    "\n",
    "# dpi of the images\n",
    "dpi = 500\n",
    "\n",
    "if save_images:\n",
    "    # FOLDERS MANAGING\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # File paths variables\n",
    "    images_dir_path = \"images\"\n",
    "\n",
    "    # Create folders to store the images\n",
    "    if not os.path.isdir(images_dir_path):\n",
    "        os.makedirs(images_dir_path)\n",
    "    \n",
    "    # Empty the 'images' folder\n",
    "    for file_name in os.listdir(images_dir_path):\n",
    "        file_path = os.path.join(images_dir_path, file_name)\n",
    "        os.remove(file_path)\n",
    "\n",
    "    #---------------------------------------------------------------------\n",
    "    # SAVING IMAGES\n",
    "    for figure_index in range(len(figures)):\n",
    "        figures[figure_index].savefig(os.path.join(images_dir_path, figures_names[figure_index]), dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVIE MAKER\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Toggle on/off the movie maker\n",
    "make_movie = False\n",
    "\n",
    "if make_movie:\n",
    "    # FOLDERS MANAGING\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # File paths variables\n",
    "    movie_dir_path = \"movie\"\n",
    "    frames_dir_path = os.path.join(movie_dir_path, \"frames\")\n",
    "    movie_frame_name_prefix = \"snapshot_img_\"\n",
    "    movie_name = \"movie.mp4\"\n",
    "\n",
    "    # Create folders to store the movie and its frames\n",
    "    if not os.path.isdir(movie_dir_path):\n",
    "        os.makedirs(frames_dir_path)\n",
    "    \n",
    "    # Empty the 'frames' folder\n",
    "    for file_name in os.listdir(frames_dir_path):\n",
    "        file_path = os.path.join(frames_dir_path, file_name)\n",
    "        os.remove(file_path)\n",
    "    \n",
    "    # Empty the 'movie' folder\n",
    "    for file_name in os.listdir(movie_dir_path):\n",
    "        file_path = os.path.join(movie_dir_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    # GENERATING FRAMES\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    # Rough estimate of the number of frames of the movie\n",
    "    # Lowering it increases the step between snapshots that are considered\n",
    "    # Use in a cycle below. If N_frames = len(snapshots) all frames are used\n",
    "    N_frames = len(snapshots)\n",
    "    \n",
    "    # If True, frames will be deleted after the movie has been assembled\n",
    "    delete_frames = True\n",
    "\n",
    "    # In order to efficiently plot data with the purpose of making a movie is useful\n",
    "    # to swap the axis of the array. This is not necessary, but otherwise plotting fucntions\n",
    "    # would take a lot of time to run\n",
    "    # \"image_pos\" works like this: new_pos[time_index][coordinate_index][particle_index]\n",
    "    # So image_pos[time_index][coordinate_index] gives the values of the specified\n",
    "    # coordinate at the specified time for all particles\n",
    "    image_pos = np.swapaxes(pos, 0, 1) # Swap particle and time\n",
    "    image_pos = np.swapaxes(image_pos, 1, 2) # Swap particle and coordinate\n",
    "\n",
    "    # Initialize a list to store the colors of each particle at any time\n",
    "    particles_colors = []\n",
    "\n",
    "    color_cm = 'black'\n",
    "    color_per = 'red'\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # Get minimum and maximum energy to normalize the colormap\n",
    "    E_k_min = np.min(particles_E_kin)\n",
    "    E_k_max = np.max(particles_E_kin)\n",
    "\n",
    "    # For every snapshot (or for some of them depending of the step of the range() call)\n",
    "    # plot the positon of every particle in 3D space\n",
    "    for time_index in tqdm(range(0, len(snapshots), int(len(snapshots) / N_frames))):\n",
    "        # Initialize a 3D plot\n",
    "        fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "        # computed_zorder=False is to allow manual setting of the order of the plots\n",
    "        ax = fig.add_subplot(projection='3d', computed_zorder=False)\n",
    "        ax.set_box_aspect(None, zoom=0.9) # To prevent z axis label to be cut off\n",
    "\n",
    "        # Plot the points and save the returned value from scatter() to make a colorbar\n",
    "        p_plot = ax.scatter(image_pos[time_index][0], image_pos[time_index][1], image_pos[time_index][2],\n",
    "                            zorder=0, c=particles_E_kin[time_index], alpha=0.8,\n",
    "                            norm=colors.LogNorm(E_k_min, E_k_max), cmap=plt.colormaps.get_cmap('Blues'))\n",
    "        ax.scatter(cm_pos[time_index][0], cm_pos[time_index][1], cm_pos[time_index][2],\n",
    "                   color=color_cm, zorder=1)\n",
    "        \n",
    "        # Perturber\n",
    "        ax.scatter(image_pos[time_index][0][perturber_indexes], image_pos[time_index][1][perturber_indexes],\n",
    "                   image_pos[time_index][2][perturber_indexes], zorder=2, color=color_per)\n",
    "        \n",
    "        # Plot the colorbar\n",
    "        cb = fig.colorbar(p_plot, ax=ax, location='right', shrink=0.75)\n",
    "        cb.set_label(r\"$E_{kin}$\", fontsize=15)\n",
    "        \n",
    "        # For the first snapshot register the axes limit\n",
    "        if time_index == 0:\n",
    "            x_lim = ax.get_xlim()\n",
    "            y_lim = ax.get_ylim()\n",
    "            z_lim = ax.get_zlim()\n",
    "        \n",
    "        # Set e cubic plot for every snapshot and fix the axes limit to the initial ones\n",
    "        ax.set_aspect('equal', 'datalim')\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        ax.set_zlim(z_lim)\n",
    "\n",
    "        # Set the snapshot time stamp as the title of every plot\n",
    "        t = float(np.format_float_scientific(time_stamp[time_index], 2))\n",
    "        ax.set_title(r\"$t={t}$\".format(t=t))\n",
    "        ax.set_xlabel(r\"$x$\")\n",
    "        ax.set_ylabel(r\"$y$\")\n",
    "        ax.set_zlabel(r\"$z$\")\n",
    "\n",
    "        # Save the current figure with a proper name\n",
    "        # zfill() is needed to achieve alphanumerical order later\n",
    "        frame_name = movie_frame_name_prefix + str(time_index).zfill(5) + \".png\"\n",
    "        frame_path = os.path.join(frames_dir_path, frame_name)\n",
    "        fig.savefig(frame_path)\n",
    "\n",
    "        # Close the current plot\n",
    "        plt.close()\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # ASSEMBLING FRAMES\n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Get all the files in the frames directory and sort them in alphanumerical order\n",
    "    movie_img_files = os.listdir(frames_dir_path)\n",
    "    movie_img_files = sorted(movie_img_files)\n",
    "\n",
    "    movie_path = os.path.join(movie_dir_path, movie_name)\n",
    "\n",
    "    # Use the imageio writer to build the movie by appending to it every frame\n",
    "    # Default fps is 10. 'I' stands for 'multiple images'\n",
    "    with iio.get_writer(movie_path, mode='I', fps=10) as writer:\n",
    "        for filename in movie_img_files:\n",
    "            image = iio.imread(os.path.join(frames_dir_path, filename)) # Get the frame\n",
    "            writer.append_data(image) # Append the frame\n",
    "            \n",
    "    # Delete individual frames if requested\n",
    "    if delete_frames:\n",
    "        for file_name in movie_img_files:\n",
    "            file_path = os.path.join(frames_dir_path, file_name)\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
